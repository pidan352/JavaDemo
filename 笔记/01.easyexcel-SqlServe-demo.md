# 1.批量插入百万数据

因为测试Excel需要准备数据，所以使用Mybatisplus的批量插入。然后又想对插入进行调优，因为Excel数据量大的时候，Java跑起来是真的慢。



## 上网查资料

https://blog.csdn.net/m0_71777195/article/details/130862000

标题是mybatis调优，用的又是mybatisplus

总结：

1.一条一条插入最慢

2.使用mybatisplus的批量插入速度快一倍

3.使用jdbc原生的executeBatch ，速度和mybatisplus的批量插入差不多，mybatisplus底层应该也是使用的这个方法

4.使用拼接sql的方式进行插入（可以是原生的，也可以用mybatisplus的自定义SQL，使用foreach拼接values），即使用sql语句的批量插入，如下

~~~sql
insert into {tableName} values(v1,v2...),(v1,v2...)...
~~~

性能最nb，比批量插入快了二十几倍



综上得出拼接SQL实现批量的速度最快，然后查找是否有不需手动拼接sql的方式。

通过在连接数据库url中添加一个参数：

~~~yaml
 url: jdbc:sqlserver://localhost;DatabaseName=text;rewriteBatchedStatements=true
~~~

添加参数之后，重新测试了mybatisplus的批量插入和jdbc的executeBatch ，速度都提升至和拼接sql差不多



通过调试发现，改参数顾名思义，就是重写批量插入，就是对于插入而言，将一批插入转换为拼接sql的形式



那为什么不默认开启呢？原因如下：

* 如果批量语句中的某些语句失败，则默认重写会导致所有语句都失败。

* 批量语句的某些语句参数不一样，则默认重写会使得查询缓存未命中。

实际考虑是否对项目有影响来决定是否要开启该参数





## 实操

mybatisplus+SQLserver

这里是为了测试做数据准备，所以开启该参数没什么影响

这里又学到一个spring的工具类StopWatch，可以用来计时

~~~java
		StopWatch stopWatch = new StopWatch();
		stopWatch.start("开始");
		//执行
		System.out.println("执行完毕："+stopWatch.getTotalTimeMillis());
~~~





1.未开重写sql参数，单线程逐条插入10万条数据

表字段就不贴了，表一共是102个字段，必填的下面的18个字段

~~~java
	@Test
	void test1() {
		StopWatch stopWatch = new StopWatch();
		stopWatch.start("开始");
		for (int i = 1; i <= 100000; i++) {
			TM04MerMultiApp tm04MerMultiApp = new TM04MerMultiApp();
			tm04MerMultiApp.setId("test" + i);
			tm04MerMultiApp.setCustomerId("test" + i);
			tm04MerMultiApp.setIsMain(0d);
			tm04MerMultiApp.setRegisterWay(0d);
			tm04MerMultiApp.setStatus(0d);
			tm04MerMultiApp.setHeadQuartersFlag(0d);
			tm04MerMultiApp.setIsTradeProcess(0d);
			tm04MerMultiApp.setIsSettlement(0d);
			tm04MerMultiApp.setAcquirerNo("test" + i);
			tm04MerMultiApp.setCreater("test" + i);
			tm04MerMultiApp.setCreateDate(LocalDateTime.now());
			tm04MerMultiApp.setLastModifier("test" + i);
			tm04MerMultiApp.setLastModifyDate(LocalDateTime.now());
			tm04MerMultiApp.setBranch("test" + i);
			tm04MerMultiApp.setProvinceBranch("test" + i);
			tm04MerMultiApp.setIsDelete("0");
			tm04MerMultiApp.setAppCategory(0d);
			tm04MerMultiApp.setAppNo(0d);

			boolean j = tm04MerMultiAppService.save(tm04MerMultiApp);
			if (j) {
				System.out.println("成功插入第" + i + "条数据");
			} else {
				System.out.println("第" + i + "条数据插入失败");
			}
		}
		stopWatch.stop();
		System.out.println("执行完毕：" + stopWatch.getTotalTimeMillis());
	}
~~~

<img src="images/image-20230602090607107.png" alt="image-20230602090607107" style="zoom:50%;" />

多次测试均在1分钟左右

之前还看到过一篇文章是对mysql逐条插入30万条数据，他测试逐条插入用了4个多小时。。。不太理解，而且他测试的表只有3个字段，是电脑配置问题还是说mybatisplus有优化，但是我开sql显示时发现也是一条一条sql执行的，不太清楚，跳过。





2.未开重写sql参数，单线程批量插入10万条数据

执行插入前清除数据

~~~sql
TRUNCATE TABLE {tableName}
~~~

每1千条数据执行一次saveBatch

~~~java
	@Test
	void test2() {
		StopWatch stopWatch = new StopWatch();
		stopWatch.start("开始");
		ArrayList<TM04MerMultiApp> list = new ArrayList<>();
		for (int i = 1; i <= 100000; i++) {
			TM04MerMultiApp tm04MerMultiApp = new TM04MerMultiApp();
			tm04MerMultiApp.setId("test" + i);
			tm04MerMultiApp.setCustomerId("test" + i);
			tm04MerMultiApp.setIsMain(0d);
			tm04MerMultiApp.setRegisterWay(0d);
			tm04MerMultiApp.setStatus(0d);
			tm04MerMultiApp.setHeadQuartersFlag(0d);
			tm04MerMultiApp.setIsTradeProcess(0d);
			tm04MerMultiApp.setIsSettlement(0d);
			tm04MerMultiApp.setAcquirerNo("test" + i);
			tm04MerMultiApp.setCreater("test" + i);
			tm04MerMultiApp.setCreateDate(LocalDateTime.now());
			tm04MerMultiApp.setLastModifier("test" + i);
			tm04MerMultiApp.setLastModifyDate(LocalDateTime.now());
			tm04MerMultiApp.setBranch("test" + i);
			tm04MerMultiApp.setProvinceBranch("test" + i);
			tm04MerMultiApp.setIsDelete("0");
			tm04MerMultiApp.setAppCategory(0d);
			tm04MerMultiApp.setAppNo(0d);

			list.add(tm04MerMultiApp);
			if (i % 1000 == 0) {
				boolean b = tm04MerMultiAppService.saveBatch(list);
				if (b) {
					System.out.println("批量插入第" + i / 1000 + "次");
				}
				list.clear();
			}
		}
		stopWatch.stop();
		System.out.println("执行完毕：" + stopWatch.getTotalTimeMillis());
	}
~~~

<img src="images/image-20230602095100867.png" alt="image-20230602095100867" style="zoom:50%;" />

多次测试都是20秒，都是毫秒级不同





3.打开sql重写参数，单线程批量插入10万条数据

~~~yaml
url: jdbc:sqlserver://localhost;DatabaseName=text;rewriteBatchedStatements=true
~~~

代码同2

<img src="images/image-20230602100054562.png" alt="image-20230602100054562" style="zoom:50%;" />

结果几乎一致，从打印的sql来看，一条sql语句之后都是参数，应该是mybatisplus已经对批量操作进行了优化

---重新测了有无重写sql参数的两个批量操作，发现sql语句是一样的，继续上网查资料，发现SQLserver的驱动似乎没有这个参数，后来发现AI是真的nt，昨天问它连接SQLserver的url中有没有这个参数说有，今天再问又说没有。。。

由于打印的sql语句并不是多值插入的形式，然后看了看了一下批量操作的实现，发现mybatisplus的实现是通过executeBatch分批提交。而rewriteBatchedStatements是将批量提交的sql进行sql重写，将sql重写成多值插入的形式。在网上看的文章mysql加了重写参数，saveBatch的性能都有很大提高。



只好自己写多值插入的自定义sql

xml：

~~~xml
<insert id="saveBatchTest" parameterType="java.util.List">
        insert into [text].[easy-excel-test].T_M04_MER_MULTI_APP( id, CUSTOMER_ID, IS_MAIN, REGISTER_WAY, STATUS, IS_SETTLEMENT, HEAD_QUARTERS_FLAG, IS_TRADE_PROCESS, ACQUIRER_NO, CREATER, CREATE_DATE, LAST_MODIFIER, LAST_MODIFY_DATE, BRANCH, PROVINCE_BRANCH, IS_DELETE, APP_CATEGORY, APP_NO )
        values
        <foreach collection="list" item="item" index="index" separator=",">
            ( #{item.id}, #{item.customerId}, #{item.isMain}, #{item.registerWay}, #{item.status}, #{item.isSettlement}, #{item.headQuartersFlag}, #{item.isTradeProcess}, #{item.acquirerNo}, #{item.creater}, #{item.createDate}, #{item.lastModifier}, #{item.lastModifyDate}, #{item.branch}, #{item.provinceBranch}, #{item.isDelete},#{item.appCategory}, #{item.appNo} )
        </foreach>
    </insert>
~~~

然后在mapper和service中补充方法

一开始一次拼接1000条数据时，直接报错，每次的参数不能超过2100个（这个好像是驱动做的限制），这里一条数据就有18个参数，所以只能将批量处理的条数降为100条

时间大概在16秒左右，提升并不大





然后将sql打印关了之后发现速度又有了一点提升，输出东西太多了，对性能有点影响





## 总结

rewriteBatchedStatements=true在SQLserver上没什么用。

将所有输出语句去掉，StopWatch也不用了，最终mybatisplus的批量插入耗时在14秒，自定义sql在12秒。

综合所有测试结果得出：

insert语句的多值插入正常情况下性能最好，前提应该要看单条数据需要传输的字段有几个，像我现在测试的每条数据有18个字段，导致了单次插入时不能拼接太多，这样操作的也多了。而上网查资料看到的测试基本上只有3,4个字段，他们使用多值插入的性能是远超于使用mybatisplus的批量插入的。所以追求速度的话，如果字段多的话，还是使用mybatisplus的批量插入较好，反之就用多值插入。

还有一个是mybatisplus单次批量插入时的数据量并不会影响执行的时间。

我看网上的测试使用mysql数据库时，rewriteBatchedStatements是可以将mybatisplus的批量插入转换成多值插入的，既然是转换为了多值插入，推测应该在字段过多的情况下，性能可能会追上不重写sql时的。这个就根据实际情况来考虑需不需要加了。字段少的话加个参数就可以重写sql，也省的自己去实现多值插入了。





最后是将百万数据插入到数据库，使用mybatisplus批量操作总耗时一分45秒。使用多值插入耗时也是来到了一分40秒，6。不过因为插入一百万条数据，一批次只有100条数据，控制台输出的信息有点多，性能稍微有点影响，将输出语句注释掉后再重新测试发现耗时为一分钟28秒。之前的差距为2秒左右，看来只有字段数会影响两种方法的差距，数据量并不会影响差距。



















